{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import SamPredictor, sam_model_registry, SamAutomaticMaskGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "\n",
    "# To save long lists to pickle files\n",
    "import pickle\n",
    "\n",
    "# Converting the data to a COCO JSON file\n",
    "import json\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Paths to Image Names and Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the CLAHE corrected images\n",
    "image_path = \"your_path_here\"\n",
    "\n",
    "# get the names of all the images in the folder\n",
    "img_names = os.listdir(image_path)\n",
    "img_names = sorted(img_names)\n",
    "\n",
    "# convert img_names to a list\n",
    "img_names = [img_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the model type as well as the checkpoint. Include the path to the checkpoint that you downloaded.\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"your_path_here/sam_vit_h_4b8939.pth\") # had highest iou scores\n",
    "# sam = sam_model_registry[\"vit_l\"](checkpoint=\"your_path_here/sam_vit_l_0b3195.pth\")\n",
    "# sam = sam_model_registry[\"vit_b\"](checkpoint=\"your_path_here/sam_vit_b_01ec64.pth\")\n",
    "\n",
    "# Set the predictor\n",
    "predictor = SamPredictor(sam)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Sam Results and Convert to COCO Style JSON annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Code here can be found at https://stackoverflow.com/questions/49494337/encode-numpy-array-using-uncompressed-rle-for-coco-dataset\n",
    "\n",
    "def encode(binary_mask):\n",
    "    rle = {\"counts\": [], \"size\": list(binary_mask.shape)}\n",
    "\n",
    "    flattened_mask = binary_mask.ravel(order=\"F\")\n",
    "    diff_arr = np.diff(flattened_mask)\n",
    "    nonzero_indices = np.where(diff_arr != 0)[0] + 1\n",
    "    lengths = np.diff(np.concatenate(([0], nonzero_indices, [len(flattened_mask)])))\n",
    "\n",
    "    # note that the odd counts are always the numbers of zeros\n",
    "    if flattened_mask[0] == 1:\n",
    "        lengths = np.concatenate(([0], lengths))\n",
    "\n",
    "    rle[\"counts\"] = lengths.tolist()\n",
    "\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sam results for all of the cryo images\n",
    "\n",
    "cryo_sam_results_combined = []\n",
    "images_dict = []\n",
    "sam_results_by_image = []\n",
    "\n",
    "# get each of the images from the image_path one at a time and perform the sam mask generation\n",
    "for i,img_name in enumerate(img_names[:]):\n",
    "    \n",
    "    img_rgb = Image.open(image_path+img_name)\n",
    "    # show the image\n",
    "    plt.imshow(img_rgb)\n",
    "    \n",
    "    img_rgb = np.array(img_rgb).astype(np.uint8)\n",
    "    img_rgb = np.repeat(img_rgb[:, :, np.newaxis], 3, axis=2)\n",
    "    sam_result = mask_generator.generate(img_rgb)\n",
    "    \n",
    "    sam_results_by_image.append(copy.deepcopy(sam_result))\n",
    "    \n",
    "    for j,annotation in enumerate(sam_result):\n",
    "        # annotation_id\n",
    "        annotation[\"id\"] = j+1\n",
    "        \n",
    "        # segmentation\n",
    "        # convert the \"segmentation\" value to binary\n",
    "        binary_mask = (annotation[\"segmentation\"]).astype(np.uint8)\n",
    "\n",
    "        rle_mask = encode(binary_mask)\n",
    "        \n",
    "        # bbox and area are already included\n",
    "        \n",
    "        # replace the \"segmentation\" value with the rle mask\n",
    "        annotation[\"segmentation\"] = rle_mask\n",
    "        \n",
    "        # iscrowd\n",
    "        annotation[\"iscrowd\"] = 1\n",
    "        \n",
    "        # attributes\n",
    "        annotation[\"attributes\"] = {}\n",
    "        annotation[\"attributes\"][\"occluded\"] = \"false\" \n",
    "        \n",
    "        # image_id\n",
    "        annotation[\"image_id\"] = i+1\n",
    "        \n",
    "        # category_id\n",
    "        annotation[\"category_id\"] = 1\n",
    "        \n",
    "        # remove point_coords, stability_score, crop_box, predicted_iou\n",
    "        annotation.pop(\"point_coords\")\n",
    "        annotation.pop(\"stability_score\")\n",
    "        annotation.pop(\"crop_box\")\n",
    "        annotation.pop(\"predicted_iou\")\n",
    "            \n",
    "    for result in sam_result:\n",
    "        cryo_sam_results_combined.append(result)\n",
    "        \n",
    "    image_dict = {}\n",
    "    image_dict[\"id\"] = i+1\n",
    "    width, height = Image.open(image_path+img_name).size\n",
    "    image_dict[\"width\"] = width\n",
    "    image_dict[\"height\"] = height\n",
    "    image_dict[\"file_name\"] = img_name\n",
    "    image_dict[\"license\"] = 0\n",
    "    image_dict[\"flickr_url\"] = \"\"\n",
    "    image_dict[\"coco_url\"] = \"\"\n",
    "    image_dict[\"date_captured\"] = 0\n",
    "    \n",
    "    images_dict.append(image_dict)\n",
    "\n",
    "# licenses, info, categories\n",
    "info_dict = {\"licenses\":[{\"name\":\"\",\"id\":0,\"url\":\"\"}],\n",
    "             \"info\":{\"contributor\":\"\",\"date_created\":\"\",\"description\":\"\",\"url\":\"\",\"version\":\"\",\"year\":\"\"},\n",
    "             \"categories\":[{\"id\":1,\"name\":\"Full\",\"supercategory\":\"\"},{\"id\":2,\"name\":\"Partial\",\"supercategory\":\"\"},{\"id\":3,\"name\":\"Empty\",\"supercategory\":\"\"}]}\n",
    "\n",
    "# Combine the dicts:\n",
    "coco_json = dict(info_dict, images = images_dict, annotations = cryo_sam_results_combined)\n",
    "\n",
    "# Save the coco_json to a json file\n",
    "with open('your_path_here/cryo_sam_results_singlepic.json', 'w') as f:\n",
    "    json.dump(coco_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the coco_json file\n",
    "with open('your_path_here/cryo_sam_results_singlepic.json', 'r') as f:\n",
    "    coco_json = json.load(f)\n",
    "    \n",
    "# load in the sam_results_by_image pickle file\n",
    "with open('your_path_here/sam_results_by_image_singlepic.pickle', 'rb') as f:\n",
    "    sam_results_by_image = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# COCO Annotations should look something like this:\n",
    "\n",
    "{\"licenses\":[\n",
    "    {\"name\":\"\",\n",
    "    \"id\":0,\n",
    "    \"url\":\"\"}],\n",
    "\n",
    "\"info\":\n",
    "    {\"contributor\":\"\",\n",
    "    \"date_created\":\"\",\n",
    "    \"description\":\"\",\n",
    "    \"url\":\"\",\n",
    "    \"version\":\"\",\n",
    "    \"year\":\"\"},\n",
    "\n",
    "\"categories\":[\n",
    "    {\"id\":1,\n",
    "    \"name\":\"Full\",\n",
    "    \"supercategory\":\"\"},...],\n",
    "\n",
    "\"images\":[\n",
    "    {\"id\":1,\n",
    "    \"width\":4096,\n",
    "    \"height\":4096,\n",
    "    \"file_name\":\"Cryo_CLAHE_0.tif\",\n",
    "    \"license\":0,\n",
    "    \"flickr_url\":\"\",\n",
    "    \"coco_url\":\"\",\n",
    "    \"date_captured\":0},...],\n",
    "\n",
    "\"annotations\":[\n",
    "    {\"id\":1,\n",
    "    \"image_id\":1,\n",
    "    \"category_id\":1,\n",
    "    \"segmentation\":\n",
    "        {\"counts\":[407382...15718566],\n",
    "        \"size\":[4096,4096]},\n",
    "    \"area\":16864.0,\n",
    "    \"bbox\":[99.0,1805.0,160.0,145.0],\n",
    "    \"iscrowd\":1,\n",
    "    \"attributes\":{\"occluded\":false}},\n",
    "    {\"id\":2,...}]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Sam results look something like this (fyi this is a background mask): \n",
    "\n",
    "[[{'segmentation': array([[False, False, False, ..., False, False, False],\n",
    "          [False, False, False, ..., False, False, False],\n",
    "          [False, False, False, ..., False, False, False],\n",
    "          ...,\n",
    "          [False, False, False, ...,  True,  True,  True],\n",
    "          [False, False, False, ...,  True,  True,  True],\n",
    "          [False, False, False, ...,  True,  True,  True]]),\n",
    "   'area': 1013196,\n",
    "   'bbox': [2753, 2297, 1342, 1798],\n",
    "   'predicted_iou': 0.9708025455474854,\n",
    "   'point_coords': [[3392.0, 3520.0]],\n",
    "   'stability_score': 0.979274570941925,\n",
    "   'crop_box': [0, 0, 4096, 4096]},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display The Sam Results For a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vit b example\n",
    "\n",
    "# for each of the images in img_names display the original image and the annotated image\n",
    "mask_annotator = sv.MaskAnnotator(color_lookup = sv.ColorLookup.CLASS)\n",
    "\n",
    "for i,img_name in enumerate(img_names[:1]):\n",
    "    img_rgb = Image.open(image_path+img_name)\n",
    "    img_rgb = np.array(img_rgb).astype(np.uint8)\n",
    "    img_rgb = np.repeat(img_rgb[:, :, np.newaxis], 3, axis=2)\n",
    "    detections = sv.Detections.from_sam(sam_result=sam_results_by_image[i])\n",
    "    \n",
    "    # create an array of 1s and 0s the length of the annotations in sam_results_by_image[i]\n",
    "    # these are the class_ids\n",
    "    class_ids = np.ones(len(sam_results_by_image[i])).astype(int)\n",
    "    \n",
    "    # add the class_ids to the detections where confidence=None, class_id=None, tracker_id=None, data={}\n",
    "    detections.class_id = class_ids\n",
    "    \n",
    "    annotated_img = mask_annotator.annotate(img_rgb.copy(), detections=detections)\n",
    "    sv.plot_images_grid(\n",
    "        images=[img_rgb, annotated_img],\n",
    "        grid_size=(1, 2),\n",
    "        titles= [\"Original\", \"Annotated\"],\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
